{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Landscape\n",
    "\n",
    "### What is Machine Learning?\n",
    "\n",
    "- Machine Learning is the science (and art) of programming computers so they can\n",
    "learn from data.\n",
    "\n",
    "### Why use Machine Learning?\n",
    "\n",
    "- Problems for which existing solutions require a lot of hand-tuning or long lists of\n",
    "rules: one Machine Learning algorithm can often simplify code and perform better.\n",
    "- Complex problems for which there is no good solution at all using a traditional\n",
    "approach: the best Machine Learning techniques can find a solution.\n",
    "- Fluctuating environments: a Machine Learning system can adapt to new data.\n",
    "- Getting insights about complex problems and large amounts of data.\n",
    "\n",
    "### Types of ML Systems\n",
    "\n",
    "1. Whether or not they are trained with human supervision\n",
    "2. Whether or not they can learn incrementally on the fly\n",
    "3. Whether they work by simply comparing new data points to known data points,\n",
    "or instead detect patterns in the training data and build a predictive model\n",
    "\n",
    "#### 1. Supervised/Unsupervised Learning\n",
    "- **Supervised:** In supervised learning, the training data you feed to the algorithm includes the desired solutions, called labels \n",
    "\n",
    "- **Unsupervised:** In unsupervised learning, as you might guess, the training data is unlabeled\n",
    "\n",
    "- **Semisupervised:** Some algorithms can deal with partially labeled training data, usually a lot of unlabeled data and a little bit of labeled data. This is called semisupervised learning, semisupervised learning algorithms are combinations of unsupervised and supervised algorithms\n",
    "\n",
    "- **Reinforcement:** Reinforcement Learning is a very different beast. The learning system, called an agent in this context, can observe the environment, select and perform actions, and get rewards in return (or penalties in the form of negative rewards). It must then learn by itself what is the best strategy, called a policy, to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation.\n",
    "\n",
    "#### 2. Batch and Online Learning\n",
    "\n",
    "- **Batch:** In batch learning, the system is incapable of learning incrementally: it must be trained using all the available data. This will generally take a lot of time and computing resources, so it is typically done offline.\n",
    "\n",
    "- **Online:** In online learning, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called mini-batches. Each learning step is fast and cheap, so the system can learn about new data on the fly\n",
    "\n",
    "#### 3. Instance-Based Versus Model-Based Learning\n",
    "\n",
    "One more way to categorize Machine Learning systems is by how they generalize, There are two main approaches to generalization:\n",
    "\n",
    "- **Instance-based:** the system learns the examples by heart, then generalizes to new cases by comparing them to the learned examples (or a subset of them), using a similarity measure\n",
    "\n",
    "- **Model-based:** build a model based on the training data, wihch is then used to make predictions without needing to store all the instances\n",
    "\n",
    "### Main Challenges\n",
    "\n",
    "#### Insufficient Quantity of Training Data\n",
    "\n",
    "It takes a lot of data for most Machine Learning algorithms to work properly. Even for very simple problems you typically need thousands of examples, and for complex problems such as image or speech recognition you may need millions of examples. However, that small- and mediumsized datasets are still very common, and it is not always easy or cheap to get extra training data, so donâ€™t abandon algorithms just yet.\n",
    "\n",
    "#### Nonrepresentative Training Data\n",
    "\n",
    "In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to. This is true whether you use instance-based learning or model-based learning.\n",
    "\n",
    "#### Poor Quality Data\n",
    "\n",
    "If your training data is full of errors, outliers, and noise, it will make it harder for the system to detect the underlying patterns.  It is often well worth the effort to spend time cleaning up your training data.\n",
    "\n",
    "#### Irrelevant Features\n",
    "\n",
    "Your system will only be capable of learning if the training data contains enough relevant features and not too many irrelevant ones. A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. (Feature Engineering)\n",
    "\n",
    "#### Overfitting Training Data\n",
    "\n",
    "Overgeneralizing is something that we humans do all too often, and unfortunately machines can fall into the same trap if we are not careful. In Machine Learning this is called overfitting: it means that the model performs well on the training data, but it does not generalize well. \n",
    "\n",
    "- **Possible Solutions:** To simplify the model by selecting one with fewer parameters, by reducing the number of attributes in the training data or by **constraining** the model, to gather more training data, to reduce the noise in the training data\n",
    "    - Constraining a model to make it simpler and reduce the risk of overfitting is called **regularization.** You want to find the right balance between fitting the training data perfectly and keeping the model simple enough to ensure that it will generalize well.\n",
    "\n",
    "The amount of regularization to apply during learning can be controlled by a **hyperparameter**. A hyperparameter is a parameter of a learning algorithm (not of the model). As such, it is not affected by the learning algorithm itself; it must be set prior to training and remains constant during training.\n",
    "\n",
    "#### Underfitting Training Data\n",
    "\n",
    "underfitting is the opposite of overfitting: it occurs when your model is too simple to learn the underlying structure of the data.\n",
    "\n",
    "- **Possible Solutions:** Selecting a more powerful model, with more parameters, Feeding better features to the learning algorithm (feature engineering), Reducing the constraints on the model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
